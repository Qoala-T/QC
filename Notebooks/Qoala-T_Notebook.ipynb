{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../Figures/KoalaFramework-Logo%20copy%202.jpg\" width=\"250\"/>\n",
    "</div>\n",
    "\n",
    "# Qoala-T Notebook, January 2020\n",
    "\n",
    "Qoala-T is a supervised learning tool that asseses accuracy of manual quality control of T1 imaging scans and their automated neuroanatomical labeling processed in FreeSurfer. It is particularly intended to use in developmental datasets. \n",
    "\n",
    "More information about Qoala-T can be found on GitHub (https://github.com/Qoala-T/QC) and in the accompanying Open Access paper:   \n",
    "Klapwijk, E.T., van de Kamp, F., Meulen, M., Peters, S., Wierenga, L.M. (2019). Qoala-T: A supervised-learning tool for quality control of FreeSurfer segmented MRI data. _NeuroImage, 189_, 116-129. https://doi.org/10.1016/j.neuroimage.2019.01.014\n",
    "\n",
    "\n",
    "The protocol of our in house developed manual QC procedure can be found here (https://github.com/Qoala-T/QC/blob/master/Qoala-T_Manual.pdf).\n",
    "\n",
    "This notebook was created by Eduard Klapwijk (https://github.com/eduardklap) based on code written by Lara Wierenga (https://github.com/larawierenga) and Olga Veth (https://github.com/OPVeth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using this notebook\n",
    "Once you have processed MRI data using FreeSurfer, you can use this notebook to extract the necessary information needed to perform Qoala-T calculations. Next, within this notebook you can run Qoala-T based on the BrainTime model. \n",
    "To run this notebook you need to use Jupyter Notebooks with the R kernel, for example by installing [Anaconda](https://www.anaconda.com/distribution/) and then follow [these instructions](https://docs.anaconda.com/anaconda/navigator/tutorials/r-lang/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: process images in FreeSurfer v6.0\n",
    "To be able to run the Qoala-T model, T1 MRI images should be processed in FreeSurfer V6.0 (https://surfer.nmr.mgh.harvard.edu/fswiki/DownloadAndInstall). This should be done before using this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install packages\n",
    "Run the next block of code to install and load the packages needed to run Qoala-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages <- c(\"caret\", \"corrplot\", \"gbm\", \"plyr\", \"randomForest\", \"e1071\",\n",
    "              \"pROC\", \"DMwR\",\"dplyr\",\"pbkrtest\",\"car\",\"pbkrtest\",\"doParallel\",\"ROSE\",\"repmis\", \"plotly\", \"r2d3\")\n",
    "if (length(setdiff(packages, rownames(installed.packages()))) > 0) {\n",
    "  install.packages(setdiff(packages, rownames(installed.packages())))  \n",
    "}\n",
    "lapply(packages, library, character.only = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run stats2table\n",
    "- Written by Olga Veth - Leiden University, MSc Computer Science student\n",
    "- Created on 30-09-2019\n",
    "- Most Recent update: 16-10-19\n",
    "- Version 3.0\n",
    "\n",
    "### Two inputs should be provided by the user of this script:\n",
    "1. Directory containing all the directories of the study participants with FreeSurfer output\n",
    "2. Name of the study and/or dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "datasetDir <- \"/path/to/data\" # Change Directory to your data\n",
    "setwd(datasetDir) \n",
    "# 2.\n",
    "dataset_name <- \"datasetname\" # Provide name of your study and/or dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run stats2table R code\n",
    "After you provided the directory and name of your dataset in the previous step, you can run the next block of code without having to make changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readAseg <- function(){\n",
    "  # The Aseg file of a subject is read in\n",
    "  # Volume_mm3 and StructName are selected\n",
    "  aseg_file <- data.frame(read.table(paste(\"./stats/aseg.stats\", sep=\"\"), row.names=1))[,c(3,4)] \n",
    "  asegTable <- t(data.frame(aseg_file[,1], row.names = aseg_file[,2])) # Aseg file - regular\n",
    "  return (asegTable)\n",
    "}\n",
    "\n",
    "readMetaAseg <- function(){\n",
    "  # The Aseg file of a subject is read in\n",
    "  # Its metadata containing 'lhCortex' etc. and their volume are saved\n",
    "  aseg_meta <- readLines(\"./stats/aseg.stats\", n=35)[14:35]\n",
    "  meta1 <- gsub(\"# \", \"\", aseg_meta)\n",
    "  meta <- t(data.frame(strsplit(meta1, \",\")))[,c(2,4)]\n",
    "  metaTable <- t(data.frame(meta[,2]))\n",
    "  colnames(metaTable) <- meta[,1]\n",
    "  return(metaTable)\n",
    "}\n",
    "\n",
    "editCol <- function(side, string, add){\n",
    "  # Change measure areas from 'Areaname'--> 'lh_Areaname_area'\n",
    "  return(paste(side, \"_\", string, add, sep=\"\"))\n",
    "}\n",
    "\n",
    "readAparc <- function(value){\n",
    "  # Aparc files of lh and rh are read in and the  area and thickness values of both files are retreved as well \n",
    "    # as the metadata measurements of both parts\n",
    "  # Areanames are formatted and eventually the data is saved into a data frame\n",
    "  sides <- c(\"lh\", \"rh\")\n",
    "  ifelse((value == \"area\"), pos <- 1, pos <- 2)\n",
    "  \n",
    "  for (x in 1:length(sides)){\n",
    "    areaThickness <- as.data.frame(read.table(paste(\"./stats/\", sides[x], \".aparc.stats\", sep=\"\"), row.names=1))[, c(2,4)]\n",
    "    rowValues <- rownames(areaThickness)\n",
    "    \n",
    "    meta <- readLines(paste(\"./stats/\", sides[x], \".aparc.stats\", sep=\"\"))[c(20, 21)] \n",
    "    meta1 <- gsub(\"# \", \"\", meta)\n",
    "    meta2 <- t(data.frame(strsplit(meta1, \",\")))[, c(2,4)]\n",
    "    meta3 <- data.frame(meta2[pos,2])\n",
    "    value2 <- gsub(\" \", \"\", meta2[pos,1])\n",
    "    \n",
    "    colnames(meta3) <- paste(sides[x], \"_\", value2, \"_\" , value, sep=\"\")\n",
    "    extra <- t(matrix(areaThickness[,pos]))\n",
    "    colnames(extra) <- paste(sides[x], \"_\", rowValues, \"_\", value, sep=\"\")\n",
    "    ifelse(x==1, aparcTable <- cbind(extra, meta3), aparcTable <- cbind(aparcTable, extra, meta3))\n",
    "  }\n",
    "  return(aparcTable)\n",
    "}\n",
    "\n",
    "readFiles <- function(){\n",
    "  # Aseg and Aparc files are read in and all the data is merged, starting with Aseg data followed with Aparc\n",
    "  asegTable <- readAseg()\n",
    "  metaTable <- readMetaAseg()\n",
    "  \n",
    "  areaAparc <- readAparc(\"area\")\n",
    "  thickAparc <- readAparc(\"thickness\")\n",
    "  \n",
    "  subjectTable <- cbind(asegTable, metaTable, areaAparc, thickAparc) # aparcMeta --> WhiteSurface\n",
    "  subjectTable <- data.frame(subjectTable)\n",
    "  return (subjectTable)\n",
    "}\n",
    "\n",
    "preprocTable <- function(subjectTable){\n",
    "  # Columnames are edited or removed from the table\n",
    "  removeCols <- c(\"*.WM-hypointensities$\",\"*.WM.hypointensities$\", \"*pole*\", \"*bankssts*\", \"VentricleChoroidVol\", \"*CerebralWhiteMatterVol\", \"\\\\bSurfaceHoles\\\\b\",\n",
    "                  \"SegVolFile.mri.aseg.mgz.\", \"*CorticalWhiteMatterVol\")\n",
    "  remove <- grep(paste(removeCols, collapse=\"|\"), colnames(subjectTable))\n",
    "  subjectTable <- subjectTable[, -remove]\n",
    "  \n",
    "  colnames(subjectTable) <- gsub(\"^X\\\\.\", \"\", colnames(subjectTable))\n",
    "  colnames(subjectTable) <- gsub(\"_\\\\.\", \"_\", colnames(subjectTable))\n",
    "  colnames(subjectTable) <- gsub(\"-\", \".\", colnames(subjectTable))\n",
    "  colnames(subjectTable) <- gsub(\" \", \"\", colnames(subjectTable))\n",
    "  \n",
    "  colnames(subjectTable)[which(colnames(subjectTable) == \"eTIV\")] <- \"EstimatedTotalIntraCranialVol\"\n",
    "  colnames(subjectTable)[which(colnames(subjectTable) %in% c(\"rd.Ventricle\", \"th.Ventricle\", \n",
    "                                                             \"5th.Ventricle\"))] <- c(\"X4th.Ventricle\", \"X3rd.Ventricle\", \"X5th.Ventricle\") # change to names\n",
    "  \n",
    "  return(subjectTable)\n",
    "}\n",
    "\n",
    "main <- function(){\n",
    "  # It loops through all subjects sub-directories in the given directory\n",
    "  # With every single subject, data is retrieved and written in a row in the final table. \n",
    "  # The result is saved into a .CSV file\n",
    "  subjects <- c()\n",
    "  first <- T\n",
    "  subjectDirs <- unique(list.dirs('.', recursive=FALSE)) # Get all sample subject\n",
    "  for (x in 0:length(subjectDirs)){\n",
    "    setwd(paste(datasetDir, subjectDirs[x], sep=\"\"))\n",
    "    statsDirs <- list.dirs('.', recursive=FALSE)\n",
    "    if (file.exists(\"./stats/aseg.stats\")){\n",
    "      subjectTable <- readFiles()\n",
    "      subjectTable <- preprocTable(subjectTable)\n",
    "      if (first == T){\n",
    "        stats2Table <- subjectTable\n",
    "        subjects <- c(subjects, substring(subjectDirs[x], 3))\n",
    "        first = F\n",
    "      } \n",
    "      else if (ncol(subjectTable) == ncol(stats2Table)&& (first == F)){\n",
    "        stats2Table <- rbind(stats2Table, subjectTable)\n",
    "        subjects <- c(subjects, substring(subjectDirs[x], 3))\n",
    "      } \n",
    "      \n",
    "    }\n",
    "  }\n",
    "  \n",
    "  stats2Table <- data.frame(stats2Table)\n",
    "  rownames(stats2Table) <- subjects\n",
    "  setwd(datasetDir)\n",
    "  write.csv(stats2Table, paste(\"FreeSurfer_Output_\", dataset_name,\".csv\", sep=\"\"))\n",
    "    }\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV output\n",
    "Now there should be a csv file called \"FreeSurfer_Ouput_(Dataset_name).csv\" in the datasetDir that was declared by the user in the previous step.  \n",
    "Let's have a look at this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read.csv(paste(\"FreeSurfer_Output_\",dataset_name,\".csv\", sep=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run the Qoala-T model on your data\n",
    "\n",
    "- written by Lara Wierenga, PhD at Leiden University\n",
    "- Created on March 2018\n",
    "- Most Recent update: 4-11-19\n",
    "- Version 1.2\n",
    "\n",
    "### Run the model and save csv output file\n",
    "Now that you have your FreeSurfer output in the right format you can run the Qoala-T model based on the BrainTime training set. The results will be saved in a csv file in your dataset directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2Table <- read.csv(paste(\"FreeSurfer_Output_\", dataset_name, \".csv\", sep=\"\"), header=T, row.names=1)\n",
    "test_data <- stats2Table\n",
    "\n",
    "githubURL <- \"https://github.com/Qoala-T/QC/blob/master/Qoala_T_model.Rdata?raw=true\"\n",
    "rf.tune <- get(load(url(githubURL)))\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "#reorder colnames of dataset to match traningset\n",
    "# -----------------------------------------------------------------\n",
    "dataset_colnames <- names(rf.tune$trainingData)[-ncol(rf.tune$trainingData)]\n",
    "testing <- test_data[,dataset_colnames]\n",
    "testing <- testing[complete.cases(testing),]\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "## External validation of unseen data on Qoala-T model \n",
    "# -----------------------------------------------------------------\n",
    "rf.pred <-  predict(rf.tune,testing)\n",
    "rf.probs <- predict(rf.tune,testing,type=\"prob\") # probability of belonging in either category (certainty..)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# Saving output\n",
    "# ----------------------------------------------------------------\n",
    "# create empty data frame\n",
    "Qoala_T_predictions <- data.frame(matrix(ncol = 4, nrow = nrow(rf.probs)))                             \n",
    "colnames(Qoala_T_predictions) = c('VisitID','Scan_QoalaT', 'Recommendation', 'manual_QC_adviced') \n",
    "\n",
    "# fill data frame\n",
    "Qoala_T_predictions$VisitID <- row.names(rf.probs)\n",
    "Qoala_T_predictions$Scan_QoalaT <- rf.probs$Include*100 \n",
    "Qoala_T_predictions$Recommendation <- rf.pred\n",
    "Qoala_T_predictions$manual_QC_adviced <- ifelse(Qoala_T_predictions$Scan_QoalaT<70&Qoala_T_predictions$Scan_QoalaT>30,\"yes\",\"no\")\n",
    "Qoala_T_predictions <- Qoala_T_predictions[order(Qoala_T_predictions$Scan_QoalaT, Qoala_T_predictions$VisitID),]\n",
    "\n",
    "\n",
    "csv_Qoala_T_predictions = paste('Qoala_T_predictions_model_based_',dataset_name,'.csv', sep = '')\n",
    "write.csv(Qoala_T_predictions, file = csv_Qoala_T_predictions, row.names=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV output\n",
    "Now there should be a csv file called \"Qoala_T_predictions_model_based_(Dataset_name).csv\" in the datasetDir.\n",
    "Let's have a look at this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "read.csv(paste('Qoala_T_predictions_model_based_',dataset_name,'.csv', sep = ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excl_rate <- table(Qoala_T_predictions$Recommendation)\n",
    "\n",
    "fill_colour <- rev(c(\"#256da8\",\"#CF4A30\"))\n",
    "font_size <- 12\n",
    "text_col <- \"Black\"\n",
    "\n",
    "p <- ggplot(Qoala_T_predictions, aes(name = VisitID, x=Scan_QoalaT,y=1,col=Recommendation)) +  \n",
    "  annotate(\"rect\", xmin=30, xmax=70, ymin=1.12, ymax=.88, alpha=0.2, fill=\"#777777\") +\n",
    "  geom_jitter(alpha=.8,height=.1,size=5) +\n",
    "  ggtitle(paste(\"Qoala-T estimation model based for \",dataset_name,\"\\nMean Qoala-T Score = \",round(mean(Qoala_T_predictions$Scan_QoalaT),1),sep=\"\")) + \n",
    "  annotate(\"text\", x=20, y=1.15, label=paste(\"Excluded = \",as.character(round(excl_rate[1])),\" scans\",sep=\"\")) + \n",
    "  annotate(\"text\", x=80, y=1.15, label=paste(\"Included = \",as.character(round(excl_rate[2])),\" scans\",sep=\"\")) + \n",
    "  scale_colour_manual(values=fill_colour) +\n",
    "  theme_bw() +\n",
    "  theme(panel.grid.major = element_blank(), \n",
    "        panel.grid.minor = element_blank(), \n",
    "        panel.border = element_blank(),\n",
    "        axis.text.x = element_text (size = font_size,color=text_col),\n",
    "        axis.text.y = element_blank(),\n",
    "        axis.title.x = element_text (size = font_size,color=text_col), \n",
    "        axis.title.y = element_blank(), \n",
    "        axis.ticks=element_blank(),\n",
    "        plot.title=element_text (size =16,color=text_col,hjust=.5)\n",
    "  )\n",
    "print(p)\n",
    "\n",
    "filename<- paste(\"Figure_Rating_model_based_\",dataset_name,\".pdf\",sep=\"\")\n",
    "dev.copy(pdf,filename,width=30/2.54, height=20/2.54)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's it! We hope these predictions help in the quality control procedure of your study.  \n",
    "  \n",
    "When using Qoala-T please include the following citation:\n",
    "  \n",
    "Klapwijk, E.T., van de Kamp, F., Meulen, M., Peters, S., Wierenga, L.M. (2019). Qoala-T: A supervised-learning tool for quality control of FreeSurfer segmented MRI data. _NeuroImage, 189_, 116-129. https://doi.org/10.1016/j.neuroimage.2019.01.014"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
